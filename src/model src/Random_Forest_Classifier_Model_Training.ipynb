{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install -U scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFwqsQjG6LRr",
        "outputId": "a58dc067-67d6-48d8-fef6-a616bd6512ef"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n"
      ],
      "metadata": {
        "id": "bChdHhiJ3pmy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data cleaning and preprocessing functions**"
      ],
      "metadata": {
        "id": "IcwKqZgip3FN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_fine(value):\n",
        "    \"\"\"Convert fine values to float, handling missing and special values\"\"\"\n",
        "    if pd.isna(value) or value == 'MA':\n",
        "        return 0\n",
        "    cleaned = str(value).replace('$', '').replace('MA', '').replace(',', '').strip()\n",
        "    return float(cleaned or 0)\n",
        "\n",
        "def convert_yes_no_to_bool(value):\n",
        "    \"\"\"Convert yes/no strings to boolean values\"\"\"\n",
        "    if isinstance(value, str):\n",
        "        return value.lower() == 'yes'\n",
        "    return bool(value)\n",
        "\n",
        "def load_and_clean_data(filepath):\n",
        "    \"\"\"Load and clean the traffic violation dataset\"\"\"\n",
        "    df = pd.read_csv(filepath)\n",
        "    df['Date Of Stop'] = pd.to_datetime(df['Date Of Stop'], format='%m/%d/%Y')\n",
        "    df['Fine'] = df['Fine'].apply(clean_fine)\n",
        "    df['Contr.Acc Fine'] = df['Contr.Acc Fine'].apply(clean_fine)\n",
        "    df['Total_Fine'] = df.apply(\n",
        "        lambda row: row['Contr.Acc Fine'] if row['Contributed To Accident'] == True\n",
        "        else row['Fine'], axis=1\n",
        "    )\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "UKGK7FUv3fmP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature engineering and preparation** **bold text**"
      ],
      "metadata": {
        "id": "1DpdJgE1qNjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_features_for_prediction(df):\n",
        "    \"\"\"Prepare features for model training\"\"\"\n",
        "    features_df = df.copy()\n",
        "\n",
        "    # Define boolean columns\n",
        "    boolean_columns = [\n",
        "        'Accident', 'Personal Injury', 'Property Damage',\n",
        "        'Fatal', 'Work Zone', 'Alcohol', 'HAZMAT',\n",
        "        'Commercial License', 'Commercial Vehicle'\n",
        "    ]\n",
        "\n",
        "    # Convert boolean columns\n",
        "    for col in boolean_columns:\n",
        "        features_df[col] = features_df[col].apply(convert_yes_no_to_bool)\n",
        "\n",
        "    # Process text descriptions\n",
        "    tfidf = TfidfVectorizer(max_features=250, stop_words='english')\n",
        "    description_features = tfidf.fit_transform(features_df['Description'].fillna(''))\n",
        "    description_df = pd.DataFrame(\n",
        "        description_features.toarray(),\n",
        "        columns=[f'desc_{i}' for i in range(description_features.shape[1])]\n",
        "    )\n",
        "\n",
        "    # Time features\n",
        "    features_df['Time_Hour'] = pd.to_datetime(features_df['Time Of Stop']).dt.hour\n",
        "\n",
        "    # Location clustering\n",
        "    location_data = features_df[['Latitude', 'Longitude']].dropna()\n",
        "    kmeans_loc = KMeans(n_clusters=5, random_state=42)\n",
        "    features_df['Location_Cluster'] = kmeans_loc.fit_predict(location_data)\n",
        "\n",
        "    # Additional feature engineering\n",
        "    for col in boolean_columns:\n",
        "        features_df[f'{col}_Flag'] = features_df[col].astype(int)\n",
        "\n",
        "    features_df['Severity_Score'] = features_df[[f'{col}_Flag' for col in boolean_columns[:7]]].sum(axis=1)\n",
        "    features_df['Is_Commercial'] = (features_df['Commercial License'] | features_df['Commercial Vehicle']).astype(int)\n",
        "    features_df['Is_Local'] = (features_df['Driver State'] == features_df['DL State']).astype(int)\n",
        "\n",
        "    # Encode categorical features\n",
        "    categorical_columns = ['Violation Type', 'VehicleType', 'SubAgency', 'Make', 'Color']\n",
        "    le_dict = {}\n",
        "    for col in categorical_columns:\n",
        "        le = LabelEncoder()\n",
        "        features_df[f'{col}_Encoded'] = le.fit_transform(features_df[col].astype(str))\n",
        "        le_dict[col] = le\n",
        "\n",
        "    # Vehicle age calculation\n",
        "    current_year = pd.Timestamp.now().year\n",
        "    features_df['Vehicle_Age'] = current_year - pd.to_numeric(features_df['Manufacture Year'], errors='coerce')\n",
        "\n",
        "    # Combine features\n",
        "    base_features = [\n",
        "        'Time_Hour', 'Location_Cluster', 'Severity_Score', 'Is_Commercial',\n",
        "        'Is_Local', 'Points', 'Vehicle_Age', 'Violation Type_Encoded',\n",
        "        'VehicleType_Encoded', 'SubAgency_Encoded', 'Make_Encoded', 'Color_Encoded'\n",
        "    ] + [f'{col}_Flag' for col in boolean_columns[:7]]\n",
        "\n",
        "    X = pd.concat([features_df[base_features], description_df], axis=1)\n",
        "    features_df['Fine_Category'] = features_df['Fine']//10\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X.fillna(0))\n",
        "\n",
        "    return {\n",
        "        'features': pd.DataFrame(X_scaled, columns=X.columns),\n",
        "        'target': features_df['Fine_Category'],\n",
        "        'label_encoders': le_dict,\n",
        "        'tfidf': tfidf,\n",
        "        'scaler': scaler,\n",
        "        'location_model': kmeans_loc,\n",
        "        'feature_names': list(X.columns),\n",
        "        'boolean_columns': boolean_columns\n",
        "    }"
      ],
      "metadata": {
        "id": "dJQ72LyKqJWi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model training**"
      ],
      "metadata": {
        "id": "k0-I9CcDqS8W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nJpjtBQU2tmP",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "class TrafficFinePredictorTrainer:\n",
        "    def __init__(self, data_path):\n",
        "        self.data_path = data_path\n",
        "        self.model_dict = None\n",
        "\n",
        "    def train_model(self):\n",
        "        \"\"\"Train the traffic fine prediction model\"\"\"\n",
        "        df = load_and_clean_data(self.data_path)\n",
        "        features_dict = prepare_features_for_prediction(df)\n",
        "\n",
        "        X = features_dict['features']\n",
        "        y = features_dict['target']\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=30\n",
        "        )\n",
        "\n",
        "        model = RandomForestClassifier(\n",
        "            n_estimators=1500,\n",
        "            max_depth=550,\n",
        "            min_samples_split=50,\n",
        "            min_samples_leaf=20,\n",
        "            class_weight='balanced',\n",
        "            random_state=30\n",
        "        )\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        self.model_dict = {\n",
        "            'model': model,\n",
        "            'label_encoders': features_dict['label_encoders'],\n",
        "            'tfidf': features_dict['tfidf'],\n",
        "            'scaler': features_dict['scaler'],\n",
        "            'location_model': features_dict['location_model'],\n",
        "            'boolean_columns': features_dict['boolean_columns'],\n",
        "            'trained_date': datetime.now(),\n",
        "            'classes': model.classes_\n",
        "        }\n",
        "\n",
        "        return self.model_dict\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the trained model**"
      ],
      "metadata": {
        "id": "hdIVs8vOqm1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(self, path='fine_prediction_model.joblib'):\n",
        "        if self.model_dict is not None:\n",
        "            joblib.dump(self.model_dict, path)"
      ],
      "metadata": {
        "id": "9MyGqqAe2wUx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = TrafficFinePredictorTrainer(\"Maryland_Traffic_Violation.csv\")\n",
        "model_dict = trainer.train_model()\n",
        "trainer.save_model()"
      ],
      "metadata": {
        "id": "FpL_ZX23rFRQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}